{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"8RZOuS9LWQvv","collapsed":true},"outputs":[],"source":["# import libraries\n","try:\n","  # %tensorflow_version only exists in Colab.\n","  !pip install tf-nightly\n","except Exception:\n","  pass\n","import tensorflow as tf\n","import pandas as pd\n","from tensorflow import keras\n","!pip install tensorflow-datasets\n","import tensorflow_datasets as tfds\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","print(tf.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lMHwYXHXCar3","collapsed":true},"outputs":[],"source":["# get data files\n","!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n","!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n","\n","train_file_path = \"train-data.tsv\"\n","test_file_path = \"valid-data.tsv\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g_h508FEClxO"},"outputs":[],"source":["print(train_file_path)\n","print(test_file_path)"]},{"cell_type":"code","source":["df_train = pd.read_csv(train_file_path, sep=\"\\t\", header=None, names=['label', 'message'])\n","df_train.head()"],"metadata":{"id":"uul2wrp_EBlH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_test = pd.read_csv(test_file_path, sep=\"\\t\", header=None, names=['label', 'message'])\n","df_test.head()"],"metadata":{"id":"r5DaiLO7E83-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(df_train))\n","print(len(df_test))"],"metadata":{"id":"KkzyaHfFFCda"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#covert categorical values into numbers\n","y_train = df_train['label'].astype('category').cat.codes\n","y_test  = df_test['label'].astype('category').cat.codes\n","y_train[:5]\n"],"metadata":{"id":"9S597r4BE8s_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bar = df_train['label'].value_counts()\n","plt.bar(bar.index, bar.values)\n","plt.xlabel('Label')\n","plt.title('Number of ham and spam messages')"],"metadata":{"id":"5JgJa366EBUN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nltk\n","nltk.download('stopwords')\n","nltk.download('wordnet')"],"metadata":{"id":"nOxjfsnNEBHf"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zOMKywn4zReN"},"outputs":[],"source":["import re\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import stopwords\n","stopwords_eng = set(stopwords.words('english'))\n","len(stopwords_eng)"]},{"cell_type":"code","source":["lemmatizer = WordNetLemmatizer()\n","\n","def clean_txt(txt):\n","    txt = re.sub(r'([^\\s\\w])+', ' ', txt)\n","    txt = \" \".join([lemmatizer.lemmatize(word) for word in txt.split()\n","                    if not word in stopwords_eng])\n","    txt = txt.lower()\n","    return txt"],"metadata":{"id":"jd1m-RI3HqfF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train = df_train['message'].apply(lambda x: clean_txt(x))\n","X_train[:5]"],"metadata":{"id":"uc4rRuetHqPx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","from keras.preprocessing import sequence"],"metadata":{"id":"2ATQ_em0N4oH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Keep top 1000 frequently occurring words\n","max_words = 1000\n","# Cut off the words after seeing 500 words in each document\n","max_len = 500"],"metadata":{"id":"zGtJgXTUN4Yp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Assign unique number to each word\n","token = Tokenizer(num_words=max_words)\n","token.fit_on_texts(X_train)"],"metadata":{"id":"ZVu2DEYvN4Lu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Transform each text to a sequence of integers\n","sequences = token.texts_to_sequences(X_train)\n","sequences[:5]"],"metadata":{"id":"rGVXElDqN3-_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Make all rows of equal length\n","sequences_matrix = sequence.pad_sequences(sequences, maxlen=max_len)\n","sequences_matrix[:5]"],"metadata":{"id":"oPLGDEPCOmU3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n","\n","embedding_dim = 50\n","max_words = 1000\n","max_len = 500\n","\n","# Define model\n","model = Sequential()\n","model.add(Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_len))\n","model.add(LSTM(64))\n","model.add(Dense(256, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.build(input_shape=(None, max_len))\n","\n","# Compile the model\n","model.compile(\n","    loss='binary_crossentropy',\n","    optimizer='RMSprop',\n","    metrics=['accuracy']\n",")\n","\n","model.summary()\n"],"metadata":{"id":"aium0EivOmHW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#EarlyStopping stops training early if the validation loss stops improving.\n","r = model.fit(sequences_matrix, y_train,\n","              batch_size=128, epochs=10,\n","              validation_split=0.2,\n","              callbacks=[tf.keras.callbacks.EarlyStopping(\n","                  monitor='val_loss', min_delta=0.0001)])"],"metadata":{"id":"2dlYWKaHOl6o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(r.history['loss'], label='loss')\n","plt.plot(r.history['val_loss'], label='val_loss')\n","plt.legend()"],"metadata":{"id":"-OEiTvg5QdS4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(r.history['accuracy'], label='acc')\n","plt.plot(r.history['val_accuracy'], label='val_acc')\n","plt.legend()"],"metadata":{"id":"ZQrvklCGQln9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#preprocessing for test data\n","#remove stopwords,special symbols\n","def preprocessing(X):\n","  x = X.apply(lambda x: clean_txt(x))\n","  x = t.texts_to_sequences(x)\n","  return sequence.pad_sequences(x, maxlen=max_len)"],"metadata":{"id":"tP07vQIlQwCg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["s = model.evaluate(preprocessing(df_test['message']), y_test)"],"metadata":{"id":"VXaBDw8HQv1w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Loss: {:.3f}, Accuracy: {:.3f}'.format(s[0], s[1]))"],"metadata":{"id":"HIF50nfbQ1to"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# function to predict messages based on model\n","# (should return list containing prediction and label, ex. [0.008318834938108921, 'ham'])\n","def predict_message(pred_text):\n","  p = model.predict(preprocessing(pd.Series([pred_text])))[0]\n","\n","  return (p[0], (\"ham\" if p<0.5 else \"spam\"))\n","\n","pred_text = \"how are you doing today?\"\n","\n","prediction = predict_message(pred_text)\n","print(prediction)"],"metadata":{"id":"vLBj7sWfQ1ch"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dxotov85SjsC"},"outputs":[],"source":["# Run this cell to test your function and model. Do not modify contents.\n","def test_predictions():\n","  test_messages = [\"how are you doing today\",\n","                   \"sale today! to stop texts call 98912460324\",\n","                   \"i dont want to go. can we try it a different day? available sat\",\n","                   \"our new mobile video service is live. just install on your phone to start watching.\",\n","                   \"you have won Â£1000 cash! call to claim your prize.\",\n","                   \"i'll bring it tomorrow. don't forget the milk.\",\n","                   \"wow, is your arm alright. that happened to me one time too\"\n","                  ]\n","\n","  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n","  passed = True\n","\n","  for msg, ans in zip(test_messages, test_answers):\n","    prediction = predict_message(msg)\n","    if prediction[1] != ans:\n","      passed = False\n","\n","  if passed:\n","    print(\"You passed the challenge. Great job!\")\n","  else:\n","    print(\"You haven't passed yet. Keep trying.\")\n","\n","test_predictions()\n"]}],"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"https://github.com/freeCodeCamp/boilerplate-neural-network-sms-text-classifier/blob/master/fcc_sms_text_classification.ipynb","timestamp":1751818349415}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}